{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"1.1.a.Save_Train_Data_15.ipynb","provenance":[{"file_id":"1wH2wqmZIGzzNlKQgI45KU6h_HChHuA_C","timestamp":1607660258274}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"I_zNKoGC9Um6"},"source":["## 1.1 Preliminiary\n","### Mount drive, import images, train and valid set, save data locally\n","\n","**Used Hyperparameter**<br>\n","Level: 0,1 images <br>\n","Number of train,val,test: 7,1,1 <br>\n","train's stride : 299 <br>\n","test's stride: 299 <br>\n","tissue percent min: 50 <br>\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"CrIymQMy5XKt","executionInfo":{"status":"ok","timestamp":1608404305925,"user_tz":300,"elapsed":853,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}},"outputId":"ad17d396-6658-4f07-817a-d9a12036109e"},"source":["import os\r\n","\r\n","# Initialization\r\n","lowest_level = 0\r\n","highest_level = 1\r\n","train_val_stride = 299\r\n","test_stride = 299\r\n","tissue_p_min = 50\r\n","\r\n","dir = '/content/drive/MyDrive/Applied_Deep_Learning_Project/'\r\n","current_dir = 'Lev_01_split_933_stride_299_pmin_50'\r\n","saving_dir = os.path.join(dir,current_dir)\r\n","saving_dir"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Applied_Deep_Learning_Project/Lev_01_split_933_stride_299_pmin_50'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"E_NxUDkQ9TsD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608404327863,"user_tz":300,"elapsed":22706,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}},"outputId":"b529b8e6-5916-4be1-bb8f-62aba1ebb58d"},"source":["# Mount drive\n","from google.colab import drive \n","drive.mount('/content/drive', force_remount=True)\n","print()\n","\n","# Check TensorFlow version\n","import tensorflow as tf \n","print(\"TF version: \", tf.__version__)\n","print()\n","\n","# Check which GPU with available RAM\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","\n","!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","\n","TF version:  2.4.0\n","\n","Found GPU at: /device:GPU:0\n","name, driver_version, memory.total [MiB]\n","Tesla P100-PCIE-16GB, 418.67, 16280 MiB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wFtertID9FwP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608404351328,"user_tz":300,"elapsed":46159,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}},"outputId":"3396ab93-7444-4a80-9a3d-c1902529e533"},"source":["!apt-get install openslide-tools  # Openslide , Install the OpenSlide C library and Python bindings\n","!apt-get install python3-openslide # After installing these libraries, use `Runtime -> restart and run all` on the menu"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  libopenslide0\n","Suggested packages:\n","  libtiff-tools\n","The following NEW packages will be installed:\n","  libopenslide0 openslide-tools\n","0 upgraded, 2 newly installed, 0 to remove and 14 not upgraded.\n","Need to get 92.5 kB of archives.\n","After this operation, 268 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenslide0 amd64 3.4.1+dfsg-2 [79.8 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 openslide-tools amd64 3.4.1+dfsg-2 [12.7 kB]\n","Fetched 92.5 kB in 0s (1,323 kB/s)\n","Selecting previously unselected package libopenslide0.\n","(Reading database ... 144865 files and directories currently installed.)\n","Preparing to unpack .../libopenslide0_3.4.1+dfsg-2_amd64.deb ...\n","Unpacking libopenslide0 (3.4.1+dfsg-2) ...\n","Selecting previously unselected package openslide-tools.\n","Preparing to unpack .../openslide-tools_3.4.1+dfsg-2_amd64.deb ...\n","Unpacking openslide-tools (3.4.1+dfsg-2) ...\n","Setting up libopenslide0 (3.4.1+dfsg-2) ...\n","Setting up openslide-tools (3.4.1+dfsg-2) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  javascript-common libjs-jquery python-asn1crypto python-blinker\n","  python-cffi-backend python-click python-colorama python-cryptography\n","  python-enum34 python-flask python-idna python-ipaddress python-itsdangerous\n","  python-jinja2 python-markupsafe python-openslide-examples python-openssl\n","  python-pkg-resources python-pyinotify python-simplejson python-six\n","  python-werkzeug python3-olefile python3-pil\n","Suggested packages:\n","  apache2 | lighttpd | httpd python-blinker-doc python-cryptography-doc\n","  python-cryptography-vectors python-enum34-doc python-flask-doc\n","  python-jinja2-doc python-openssl-doc python-openssl-dbg python-setuptools\n","  python-pyinotify-doc ipython python-genshi python-lxml python-greenlet\n","  python-redis python-pylibmc | python-memcache python-termcolor\n","  python-watchdog python-werkzeug-doc python-pil-doc python3-pil-dbg\n","The following NEW packages will be installed:\n","  javascript-common libjs-jquery python-asn1crypto python-blinker\n","  python-cffi-backend python-click python-colorama python-cryptography\n","  python-enum34 python-flask python-idna python-ipaddress python-itsdangerous\n","  python-jinja2 python-markupsafe python-openslide-examples python-openssl\n","  python-pkg-resources python-pyinotify python-simplejson python-six\n","  python-werkzeug python3-olefile python3-openslide python3-pil\n","0 upgraded, 25 newly installed, 0 to remove and 14 not upgraded.\n","Need to get 1,917 kB of archives.\n","After this operation, 9,528 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-asn1crypto all 0.24.0-1 [72.7 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-blinker all 1.4+dfsg1-0.1 [13.0 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cffi-backend amd64 1.11.5-1 [63.4 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-colorama all 0.3.7-1 [22.6 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-click all 6.7-3 [56.4 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-enum34 all 1.1.6-2 [34.8 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-idna all 2.6-1 [32.4 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-ipaddress all 1.0.17-1 [18.2 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-cryptography amd64 2.1.4-1ubuntu1.4 [276 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-itsdangerous all 0.24+dfsg1-2 [11.9 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-markupsafe amd64 1.0-1build1 [13.0 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-jinja2 all 2.10-1ubuntu0.18.04.1 [94.8 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-werkzeug all 0.14.1+dfsg1-1ubuntu0.1 [174 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-flask all 0.12.2-3ubuntu0.1 [62.4 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-pil amd64 5.1.0-1ubuntu0.3 [330 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-openslide amd64 1.1.1-2ubuntu4 [16.1 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-openslide-examples all 1.1.1-2ubuntu4 [168 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-openssl all 17.5.0-1ubuntu1 [41.3 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pyinotify all 0.9.6-1 [24.6 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-simplejson amd64 3.13.2-1 [61.2 kB]\n","Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-olefile all 0.45.1-1 [33.3 kB]\n","Fetched 1,917 kB in 0s (15.2 MB/s)\n","Selecting previously unselected package javascript-common.\n","(Reading database ... 144880 files and directories currently installed.)\n","Preparing to unpack .../00-javascript-common_11_all.deb ...\n","Unpacking javascript-common (11) ...\n","Selecting previously unselected package libjs-jquery.\n","Preparing to unpack .../01-libjs-jquery_3.2.1-1_all.deb ...\n","Unpacking libjs-jquery (3.2.1-1) ...\n","Selecting previously unselected package python-asn1crypto.\n","Preparing to unpack .../02-python-asn1crypto_0.24.0-1_all.deb ...\n","Unpacking python-asn1crypto (0.24.0-1) ...\n","Selecting previously unselected package python-blinker.\n","Preparing to unpack .../03-python-blinker_1.4+dfsg1-0.1_all.deb ...\n","Unpacking python-blinker (1.4+dfsg1-0.1) ...\n","Selecting previously unselected package python-cffi-backend.\n","Preparing to unpack .../04-python-cffi-backend_1.11.5-1_amd64.deb ...\n","Unpacking python-cffi-backend (1.11.5-1) ...\n","Selecting previously unselected package python-colorama.\n","Preparing to unpack .../05-python-colorama_0.3.7-1_all.deb ...\n","Unpacking python-colorama (0.3.7-1) ...\n","Selecting previously unselected package python-click.\n","Preparing to unpack .../06-python-click_6.7-3_all.deb ...\n","Unpacking python-click (6.7-3) ...\n","Selecting previously unselected package python-enum34.\n","Preparing to unpack .../07-python-enum34_1.1.6-2_all.deb ...\n","Unpacking python-enum34 (1.1.6-2) ...\n","Selecting previously unselected package python-idna.\n","Preparing to unpack .../08-python-idna_2.6-1_all.deb ...\n","Unpacking python-idna (2.6-1) ...\n","Selecting previously unselected package python-ipaddress.\n","Preparing to unpack .../09-python-ipaddress_1.0.17-1_all.deb ...\n","Unpacking python-ipaddress (1.0.17-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../10-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-cryptography.\n","Preparing to unpack .../11-python-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n","Unpacking python-cryptography (2.1.4-1ubuntu1.4) ...\n","Selecting previously unselected package python-itsdangerous.\n","Preparing to unpack .../12-python-itsdangerous_0.24+dfsg1-2_all.deb ...\n","Unpacking python-itsdangerous (0.24+dfsg1-2) ...\n","Selecting previously unselected package python-markupsafe.\n","Preparing to unpack .../13-python-markupsafe_1.0-1build1_amd64.deb ...\n","Unpacking python-markupsafe (1.0-1build1) ...\n","Selecting previously unselected package python-jinja2.\n","Preparing to unpack .../14-python-jinja2_2.10-1ubuntu0.18.04.1_all.deb ...\n","Unpacking python-jinja2 (2.10-1ubuntu0.18.04.1) ...\n","Selecting previously unselected package python-werkzeug.\n","Preparing to unpack .../15-python-werkzeug_0.14.1+dfsg1-1ubuntu0.1_all.deb ...\n","Unpacking python-werkzeug (0.14.1+dfsg1-1ubuntu0.1) ...\n","Selecting previously unselected package python-flask.\n","Preparing to unpack .../16-python-flask_0.12.2-3ubuntu0.1_all.deb ...\n","Unpacking python-flask (0.12.2-3ubuntu0.1) ...\n","Selecting previously unselected package python3-pil:amd64.\n","Preparing to unpack .../17-python3-pil_5.1.0-1ubuntu0.3_amd64.deb ...\n","Unpacking python3-pil:amd64 (5.1.0-1ubuntu0.3) ...\n","Selecting previously unselected package python3-openslide.\n","Preparing to unpack .../18-python3-openslide_1.1.1-2ubuntu4_amd64.deb ...\n","Unpacking python3-openslide (1.1.1-2ubuntu4) ...\n","Selecting previously unselected package python-openslide-examples.\n","Preparing to unpack .../19-python-openslide-examples_1.1.1-2ubuntu4_all.deb ...\n","Unpacking python-openslide-examples (1.1.1-2ubuntu4) ...\n","Selecting previously unselected package python-openssl.\n","Preparing to unpack .../20-python-openssl_17.5.0-1ubuntu1_all.deb ...\n","Unpacking python-openssl (17.5.0-1ubuntu1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../21-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-pyinotify.\n","Preparing to unpack .../22-python-pyinotify_0.9.6-1_all.deb ...\n","Unpacking python-pyinotify (0.9.6-1) ...\n","Selecting previously unselected package python-simplejson.\n","Preparing to unpack .../23-python-simplejson_3.13.2-1_amd64.deb ...\n","Unpacking python-simplejson (3.13.2-1) ...\n","Selecting previously unselected package python3-olefile.\n","Preparing to unpack .../24-python3-olefile_0.45.1-1_all.deb ...\n","Unpacking python3-olefile (0.45.1-1) ...\n","Setting up python-idna (2.6-1) ...\n","Setting up python-simplejson (3.13.2-1) ...\n","Setting up libjs-jquery (3.2.1-1) ...\n","Setting up python-asn1crypto (0.24.0-1) ...\n","Setting up python3-pil:amd64 (5.1.0-1ubuntu0.3) ...\n","Setting up python-blinker (1.4+dfsg1-0.1) ...\n","Setting up python3-olefile (0.45.1-1) ...\n","Setting up python-colorama (0.3.7-1) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-markupsafe (1.0-1build1) ...\n","Setting up python-werkzeug (0.14.1+dfsg1-1ubuntu0.1) ...\n","Setting up python-pyinotify (0.9.6-1) ...\n","Setting up python-cffi-backend (1.11.5-1) ...\n","Setting up python3-openslide (1.1.1-2ubuntu4) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-enum34 (1.1.6-2) ...\n","Setting up javascript-common (11) ...\n","Setting up python-itsdangerous (0.24+dfsg1-2) ...\n","Setting up python-ipaddress (1.0.17-1) ...\n","Setting up python-jinja2 (2.10-1ubuntu0.18.04.1) ...\n","Setting up python-click (6.7-3) ...\n","Setting up python-cryptography (2.1.4-1ubuntu1.4) ...\n","Setting up python-flask (0.12.2-3ubuntu0.1) ...\n","Setting up python-openssl (17.5.0-1ubuntu1) ...\n","Setting up python-openslide-examples (1.1.1-2ubuntu4) ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WWTPFoDTx1Qm","executionInfo":{"status":"ok","timestamp":1608404352242,"user_tz":300,"elapsed":47071,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["import numpy as np\n","from openslide import open_slide, __library_version__ as openslide_version\n","\n","from openslide import open_slide, __library_version__ as openslide_version\n","import os\n","# from PIL import Image\n","from skimage.color import rgb2gray\n","from sklearn.model_selection import train_test_split\n","from itertools import chain\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D, concatenate\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import plot_model\n","from matplotlib.patches import Rectangle\n","import re\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"x6CeC7Zf9azt","executionInfo":{"status":"ok","timestamp":1608404352242,"user_tz":300,"elapsed":47069,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["def get_open_slide(tissue_path, mask_path, return_tissue):\n","# Function that opens an image based on path\n","# Note: return_tissue = boolean value, \n","#      Ture -> reads tissue img, False -> reads masks image\n","\n","  slide = open_slide(tissue_path)\n","  print (\"Read WSI from %s with width: %d, height: %d\" % (tissue_path, \n","                                                          slide.level_dimensions[0][0], \n","                                                          slide.level_dimensions[0][1]))\n","  mask = open_slide(mask_path)\n","  print (\"Read tumor mask from %s\" % (mask_path))\n","\n","  print(\"Slide includes %d levels\", min(len(slide.level_dimensions),len(mask.level_dimensions)))\n","  for i in range(min(len(slide.level_dimensions),len(mask.level_dimensions))):\n","      print(\"Level %d, dimensions: %s downsample factor %d\" % (i, \n","                                                              slide.level_dimensions[i], \n","                                                              slide.level_downsamples[i]))\n","      assert mask.level_dimensions[i][0] == slide.level_dimensions[i][0]\n","      assert mask.level_dimensions[i][1] == slide.level_dimensions[i][1]\n","\n","  # Verify downsampling works as expected\n","  width, height = slide.level_dimensions[7]\n","  assert width * slide.level_downsamples[7] == slide.level_dimensions[0][0]\n","  assert height * slide.level_downsamples[7] == slide.level_dimensions[0][1]\n","\n","  if (return_tissue):\n","    return slide\n","  else:\n","    return mask"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"aCh3HFAk9g6F","executionInfo":{"status":"ok","timestamp":1608404352243,"user_tz":300,"elapsed":47068,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["# See https://openslide.org/api/python/#openslide.OpenSlide.read_region\n","# Note: x,y coords are with respect to level 0. \n","# There is an example below of working with coordinates with respect to a higher zoom level.\n","\n","# Read a region from the slide, Return a numpy RBG array\n","def read_slide(slide, x, y, level, width, height, as_float=False):\n","    im = slide.read_region((x,y), level, (width, height))\n","    im = im.convert('RGB') # drop the alpha channel\n","    if as_float:\n","        im = np.asarray(im, dtype=np.float32)\n","    else:\n","        im = np.asarray(im)\n","    assert im.shape == (height, width, 3)\n","    return im"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"uoip8-z8ya5U","executionInfo":{"status":"ok","timestamp":1608404352243,"user_tz":300,"elapsed":47066,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["# Gets difference of two lists using set operator\n","def difference(L1, L2):\n","    return (list(list(set(L1)-set(L2)) + list(set(L2)-set(L1))))\n","\n","# detect and remove if number of images and masks are different\n","def balance_imgs(image_path_l, mask_path_l):\n","  img_num_l = [re.findall(r'\\d+', string)[0] for string in image_path_l ] # list of image numbers\n","  mask_num_l = [re.findall(r'\\d+', string)[0] for string in mask_path_l ] # list of mask's image numbers\n","\n","  img_len = len(img_num_l)\n","  mask_len = len(mask_num_l)\n","\n","  # delete images that are not same in number of lengths automatically\n","  if img_len != mask_len:\n","    print(\"Tissue image length: {}\".format(len(image_path_l)))\n","    print(\"Mask image length: {}\".format(len(mask_path_l)))\n","\n","    diff_img_num = difference(img_num_l,mask_num_l)[0]\n","\n","    if img_len > mask_len: # i.e. need to find extra image and delete\n","      print(\"Removed image number {} since there is no corresponding biopsy image\".format(diff_img_num))\n","      del image_path_l[img_num_l.index(diff_img_num)]\n","\n","    else: \n","      print(\"Removed mask number {} since there is no corresponding  image\".format(diff_img_num))\n","      del mask_path_l[mask_num_l.index(diff_img_num)]\n","\n","  return image_path_l, mask_path_l"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"3zvmW3bfyemc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608404354227,"user_tz":300,"elapsed":49039,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}},"outputId":"e170a175-98d8-4b9c-8091-d3eb1bf2e950"},"source":["# Note: since importing slides from Professor's Google API does not work sometimes,\n","# we downloaded the images to 'locally' in Google Drive\n","directory = '/content/drive/MyDrive/Applied_Deep_Learning_Project/slides_local/'\n","\n","biopsy_path_list = []\n","mask_path_list = []\n","\n","for file in os.scandir(directory):\n","  \n","  if (\"tif\" in file.name):\n","    if (\"mask\" in file.name):\n","      mask_path_list.append(file.path) \n","  \n","    else:\n","      biopsy_path_list.append(file.path)\n","\n","# # Automatically removes images that are not both exists in image and masks\n","biopsy_path_list,mask_path_list = balance_imgs(biopsy_path_list,mask_path_list)\n","\n","biopsy_path_list.sort()\n","mask_path_list.sort()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Tissue image length: 22\n","Mask image length: 21\n","Removed image number 038 since there is no corresponding biopsy image\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2_v5SW89zeEn"},"source":["####  Since the number of biopsy and mask images are different, image number 38 got deleted from the initially given sample. Also, we removed some other biopsy/mask images that do not have cancer percentage high enough.<br>"]},{"cell_type":"code","metadata":{"id":"AZSBSo79-xC1","executionInfo":{"status":"ok","timestamp":1608404354227,"user_tz":300,"elapsed":49038,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["def extract_img_numbers(string_list):\r\n","  int_list = []\r\n","  for str in string_list:\r\n","    img_num = re.findall(r'\\d+', str)[0]\r\n","    int_list.append(int(img_num))\r\n","\r\n","  return sorted(int_list)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"zH_9ZXY0-qQJ","executionInfo":{"status":"ok","timestamp":1608404354228,"user_tz":300,"elapsed":49036,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["# train_index = [2,4,5,6,7,15,17,19,20,1,3,8,9,10,14]\r\n","# valid_index = [0,12,18]\r\n","# test_index = [11,13,16]\r\n","\r\n","# train_index = [2,4,5,6,7,12,16,17,18,20]\r\n","# test_index = [11,13,17]\r\n","# valid_index = [0,15,19]"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KNw3JeRK7JG0"},"source":["### Decided to use 9 images for train set, 3 for valid set, and 3 for test set"]},{"cell_type":"code","metadata":{"id":"pFDB1F-KOAG9","executionInfo":{"status":"ok","timestamp":1608404354228,"user_tz":300,"elapsed":49033,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["train_index = [12,15,17,19,20]\n","train_index = [15]\n","valid_index = [13]\n","test_index = [16]\n","\n","biopsy_train = [biopsy_path_list[i] for i in train_index]\n","biopsy_test = [biopsy_path_list[i] for i in test_index]\n","biopsy_valid = [biopsy_path_list[i] for i in valid_index]\n","mask_train = [mask_path_list[i] for i in train_index]\n","mask_test = [mask_path_list[i] for i in test_index]\n","mask_valid = [mask_path_list[i] for i in valid_index]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"vT75LDYv_7Ee","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608404354229,"user_tz":300,"elapsed":49023,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}},"outputId":"f7a69945-b5b7-4e2e-8f7d-cc52e723ea0a"},"source":["print(\"Total num of samples used: \", len(biopsy_train) + len(biopsy_valid) +len(biopsy_test))\r\n","print(\"Each train/val/test set length: \\n biopsy -> train: {} val: {} test: {} \\n Mask -> train: {} val: {} test: {}\".format(\r\n","     len(biopsy_train), len(biopsy_valid), len(biopsy_test), \r\n","     len(mask_train), len(mask_valid), len(mask_test)  ))\r\n","\r\n","print()\r\n","print(\"Biopsy img number in train set: {}\".format(extract_img_numbers(biopsy_train)))\r\n","print(\"Biopsy img number in valid set: {}\".format(extract_img_numbers(biopsy_valid)))\r\n","print(\"Biopsy img number in test set: {}\".format(extract_img_numbers(biopsy_test)))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Total num of samples used:  3\n","Each train/val/test set length: \n"," biopsy -> train: 1 val: 1 test: 1 \n"," Mask -> train: 1 val: 1 test: 1\n","\n","Biopsy img number in train set: [84]\n","Biopsy img number in valid set: [78]\n","Biopsy img number in test set: [91]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D595-G-g-jYT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608404368490,"user_tz":300,"elapsed":63271,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}},"outputId":"f4fce3ae-af18-4187-e03b-a0b8e4f631e6"},"source":["#Getting the slides using each of the train/test/valid directory\n","biopsy_slides_train = [get_open_slide(x,y,True) for x,y in zip(biopsy_train, mask_train)] # Ture -> reads tumor img, False -> reads masks image\n","mask_slides_train = [get_open_slide(x,y,False) for x,y in zip(biopsy_train, mask_train)]\n","\n","biopsy_slides_valid = [get_open_slide(x,y,True) for x,y in zip(biopsy_valid, mask_valid)]\n","mask_slides_valid = [get_open_slide(x,y,False) for x,y in zip(biopsy_valid, mask_valid)]\n","\n","biopsy_slides_test = [get_open_slide(x,y,True) for x,y in zip(biopsy_test, mask_test)]\n","mask_slides_test = [get_open_slide(x,y,False) for x,y in zip(biopsy_test, mask_test)]"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Read WSI from /content/drive/MyDrive/Applied_Deep_Learning_Project/slides_local/tumor_084.tif with width: 65536, height: 86016\n","Read tumor mask from /content/drive/MyDrive/Applied_Deep_Learning_Project/slides_local/tumor_084_mask.tif\n","Slide includes %d levels 8\n","Level 0, dimensions: (65536, 86016) downsample factor 1\n","Level 1, dimensions: (32768, 43008) downsample factor 2\n","Level 2, dimensions: (16384, 21504) downsample factor 4\n","Level 3, dimensions: (8192, 10752) downsample factor 8\n","Level 4, dimensions: (4096, 5376) downsample factor 16\n","Level 5, dimensions: (2048, 2688) downsample factor 32\n","Level 6, dimensions: (1024, 1344) downsample factor 64\n","Level 7, dimensions: (512, 672) downsample factor 128\n","Read WSI from /content/drive/MyDrive/Applied_Deep_Learning_Project/slides_local/tumor_084.tif with width: 65536, height: 86016\n","Read tumor mask from /content/drive/MyDrive/Applied_Deep_Learning_Project/slides_local/tumor_084_mask.tif\n","Slide includes %d levels 8\n","Level 0, dimensions: (65536, 86016) downsample factor 1\n","Level 1, dimensions: (32768, 43008) downsample factor 2\n","Level 2, dimensions: (16384, 21504) downsample factor 4\n","Level 3, dimensions: (8192, 10752) downsample factor 8\n","Level 4, dimensions: (4096, 5376) downsample factor 16\n","Level 5, dimensions: (2048, 2688) downsample factor 32\n","Level 6, dimensions: (1024, 1344) downsample factor 64\n","Level 7, dimensions: (512, 672) downsample factor 128\n","Read WSI from /content/drive/MyDrive/Applied_Deep_Learning_Project/slides_local/tumor_078.tif with width: 94208, height: 111104\n","Read tumor mask from /content/drive/MyDrive/Applied_Deep_Learning_Project/slides_local/tumor_078_mask.tif\n","Slide includes %d levels 9\n","Level 0, dimensions: (94208, 111104) downsample factor 1\n","Level 1, dimensions: (47104, 55552) downsample factor 2\n","Level 2, dimensions: (23552, 27776) downsample factor 4\n","Level 3, dimensions: (11776, 13888) downsample factor 8\n","Level 4, dimensions: (5888, 6944) downsample factor 16\n","Level 5, dimensions: (2944, 3472) downsample factor 32\n","Level 6, dimensions: (1472, 1736) downsample factor 64\n","Level 7, dimensions: (736, 868) downsample factor 128\n","Level 8, dimensions: (368, 434) downsample factor 256\n","Read WSI from /content/drive/MyDrive/Applied_Deep_Learning_Project/slides_local/tumor_078.tif with width: 94208, height: 111104\n","Read tumor mask from /content/drive/MyDrive/Applied_Deep_Learning_Project/slides_local/tumor_078_mask.tif\n","Slide includes %d levels 9\n","Level 0, dimensions: (94208, 111104) downsample factor 1\n","Level 1, dimensions: (47104, 55552) downsample factor 2\n","Level 2, dimensions: (23552, 27776) downsample factor 4\n","Level 3, dimensions: (11776, 13888) downsample factor 8\n","Level 4, dimensions: (5888, 6944) downsample factor 16\n","Level 5, dimensions: (2944, 3472) downsample factor 32\n","Level 6, dimensions: (1472, 1736) downsample factor 64\n","Level 7, dimensions: (736, 868) downsample factor 128\n","Level 8, dimensions: (368, 434) downsample factor 256\n","Read WSI from /content/drive/MyDrive/Applied_Deep_Learning_Project/slides_local/tumor_091.tif with width: 61440, height: 53760\n","Read tumor mask from /content/drive/MyDrive/Applied_Deep_Learning_Project/slides_local/tumor_091_mask.tif\n","Slide includes %d levels 8\n","Level 0, dimensions: (61440, 53760) downsample factor 1\n","Level 1, dimensions: (30720, 26880) downsample factor 2\n","Level 2, dimensions: (15360, 13440) downsample factor 4\n","Level 3, dimensions: (7680, 6720) downsample factor 8\n","Level 4, dimensions: (3840, 3360) downsample factor 16\n","Level 5, dimensions: (1920, 1680) downsample factor 32\n","Level 6, dimensions: (960, 840) downsample factor 64\n","Level 7, dimensions: (480, 420) downsample factor 128\n","Read WSI from /content/drive/MyDrive/Applied_Deep_Learning_Project/slides_local/tumor_091.tif with width: 61440, height: 53760\n","Read tumor mask from /content/drive/MyDrive/Applied_Deep_Learning_Project/slides_local/tumor_091_mask.tif\n","Slide includes %d levels 8\n","Level 0, dimensions: (61440, 53760) downsample factor 1\n","Level 1, dimensions: (30720, 26880) downsample factor 2\n","Level 2, dimensions: (15360, 13440) downsample factor 4\n","Level 3, dimensions: (7680, 6720) downsample factor 8\n","Level 4, dimensions: (3840, 3360) downsample factor 16\n","Level 5, dimensions: (1920, 1680) downsample factor 32\n","Level 6, dimensions: (960, 840) downsample factor 64\n","Level 7, dimensions: (480, 420) downsample factor 128\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qVbZ0Z9lxozc"},"source":["#### Use filter to facilitate training proces\n","##### i.e. regions where tissue is -> where grey value is lower than 0.8"]},{"cell_type":"code","metadata":{"id":"OoiysdHsxoap","executionInfo":{"status":"ok","timestamp":1608404368492,"user_tz":300,"elapsed":63271,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["# As mentioned in class, we can improve efficiency by ignoring non-tissue areas \n","# of the slide. We'll find these by looking for all gray regions.\n","def find_tissue_pixels(image, intensity=0.8):\n","    im_gray = rgb2gray(image)\n","    assert im_gray.shape == (image.shape[0], image.shape[1])\n","    indices = np.where(im_gray <= intensity)\n","    return len(indices[0]) # i.e. return length of number of pixels that have lower intensity\n","\n","# A modified version of the finding tissue pixel \n","# Returns True if area of present biopsy image is above the threshold, min_percentage,\n","def pass_tissue_percentage(slide_image, tissue_p_min, w, h):\n","  tissue_pixels = find_tissue_pixels(slide_image)\n","  percent_tissue = tissue_pixels/ float(w*h) * 100\n","\n","  if percent_tissue > tissue_p_min:\n","    # print(\"----------------\",(\"%.2f\" % round(percent_tissue, 2)))\n","    return True\n","  else:\n","    return False\n","\n","# test whether a patch has cancer or not\n","def has_cancer(patch):\n","  return (sum(sum(chain.from_iterable(patch))) != 0) * 1  #i.e. returns 1 if a patch has a caner, else 0"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xCxrTuWsT9S","executionInfo":{"status":"ok","timestamp":1608404368492,"user_tz":300,"elapsed":63269,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["def downsample_factor(slide, level):\n","\n","  return (int(slide.level_downsamples[level]))\n","\n","\n","# Transforms a coordinate associated with a current zoom level\n","def transform_coord(slide, input_coord, base_level, current_level, patch_size):\n","\n","  base_lev_factor = downsample_factor(slide,base_level)\n","  current_lev_factor = downsample_factor(slide,current_level)\n","\n","  new_coord = input_coord * base_lev_factor - int(patch_size/2) * current_lev_factor\n","  return new_coord\n","\n","\n","# Reads slide according to the transformed coordinate\n","def read_zoom_slide(slide, x_input, y_input, base_lev, current_lev, patch_size):\n","\n","  slide = read_slide(slide, \n","                     transform_coord(slide, x_input, base_lev, current_lev, patch_size ),\n","                     transform_coord(slide, y_input, base_lev, current_lev, patch_size ),\n","                     level = current_lev, width = patch_size, height = patch_size)\n","  return slide\n","\n","# Computes a relative magnification difference between two zoom levels\n","def compute_relative_mag(base_lev, current_lev):\n","\n","  result = 2 ** (base_lev - current_lev)  # i.e. base_lev = 7, current_lev =5, then current level is zoomed 4 times more\n","  return result\n","\n","\n","# Computes Rectangle with appropriate coordinates in the current zoom level,\n","# with relative to the base level (most zoomed out level) \n","def compute_rectangle(relative_magnification, patch_size = 299, center_size = 128):\n","\n","  return Rectangle((int(patch_size / 2) - int(center_size / (2 ** (relative_magnification + 1))),\n","                  int(patch_size / 2) - int(center_size / (2 ** (relative_magnification + 1)))),\n","                  center_size / (2**relative_magnification),\n","                  center_size  / (2**relative_magnification),\n","                  facecolor='none', edgecolor='red')"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"BzqpP5_cMk-3","executionInfo":{"status":"ok","timestamp":1608404368493,"user_tz":300,"elapsed":63269,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["def print_patches(patch_list, base_l, current_l):\n","  number_patches = len(patch_list)\n","  fig, axes = plt.subplots(nrows=1, ncols=number_patches, figsize=(15,10))\n","  for idx, slide in enumerate(patch_list):\n","    axes[idx].imshow(slide)\n","    axes[idx].add_patch(compute_rectangle(idx))\n","\n","def print_masks(patch_list, base_l, current_l):\n","  number_patches = len(patch_list)\n","  fig, axes = plt.subplots(nrows=1, ncols=number_patches, figsize=(15,10))\n","  for idx, slide in enumerate(patch_list):\n","    axes[idx].imshow(slide[:,:,0])\n","    axes[idx].add_patch(compute_rectangle(idx))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOIZMnUOyzgA","executionInfo":{"status":"ok","timestamp":1608404368493,"user_tz":300,"elapsed":63267,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["  def index_values_l( mylist, value): # print indices in a list where value is repetitive\r\n","      return [i for i,x in enumerate(mylist) if x==value]\r\n","\r\n","  def undersampling_labels(label_list):\r\n","    indicies_1 = index_values_l(label_list,1)\r\n","    indicies_0 = index_values_l(label_list,0)\r\n","    # print(\"1: \",indicies_1, \"length: \", len(indicies_1 ))\r\n","    # print(\"0: \",indicies_0,  \"length: \", len(indicies_0 ))\r\n","    # print()\r\n","\r\n","    temp = list(zip(indicies_1, indicies_0)) \r\n","    np.random.shuffle(temp) \r\n","    shuffle_i_1, shuffle_i_0 = zip(*temp) \r\n","\r\n","    min_length = min(len(indicies_1),len(indicies_0))\r\n","    # print(\"min_length: \", min_length)\r\n","    # print()\r\n","    # print(\"index of 1: \", indicies_1[:min_length])\r\n","    # print(\"index of 0: \", indicies_0[:min_length])\r\n","\r\n","    balanced_index = sorted(indicies_1[:min_length] + indicies_0[:min_length]) # i.e. sorted\r\n","    return balanced_index\r\n","\r\n","\r\n","# #testing\r\n","# abcd = [1,0,0,0,0,0,1,1,0,0,0,0,0,0]\r\n","# undersampling_labels(abcd)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"3N1BAAfND0fB","executionInfo":{"status":"ok","timestamp":1608404368978,"user_tz":300,"elapsed":63749,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["def create_patches(biopsy_slide, mask_slide, lowest_level = 5, highest_level = 7, apply_filter = False, stride = 100, tissue_p_min = 50):\n","\n","  p_size = 299  # patch size\n","  stride = stride  # need to chnage (here, for zoom level 5, which is lowest level)\n","\n","  tissue_p_min = tissue_p_min  # i.e. treshold of minimum percentage of tissue converaged in percentage\n","                # i.e. if patch has more than 10% of tissue pixels, then take it\n","  biopsy_list = []\n","  label_list = []\n","\n","  # Starting center coordinates\n","  x = int(p_size/2) # i.e. 150\n","  y = int(p_size/2)\n","\n","  biopsy_w_high = biopsy_slide.level_dimensions[highest_level][0]\n","  biopsy_h_high = biopsy_slide.level_dimensions[highest_level][1]\n","\n","  biopsy_w_low = biopsy_slide.level_dimensions[lowest_level][0]\n","  biopsy_h_low = biopsy_slide.level_dimensions[lowest_level][1]\n","\n","  # print(biopsy_w_high, biopsy_w_high * slide.level_downsamples[base])\n","\n","  biopsy_list_batch = []\n","  \n","  run = True\n","\n","  global patch_counter\n","  patch_counter=0\n","  patch_x_counter=0\n","  patch_y_counter=0\n","\n","  print(\"lowest dim shape:\",biopsy_w_low, \" \", biopsy_h_low )\n","\n","  # print(\"Applying filtering? : -> \", apply_filter)\n","\n","  while(run):\n","    # print(\"Coordinate: \" + str(x) + \" \" + str(y))\n","     \n","\n","    if (y < biopsy_h_high  - 299//2):  # i.e. slide based on highest level since it is most zoomed out version\n","      if (x < biopsy_w_high - 299//2):\n","        biopsy_list_batch = []\n","\n","        slide_image_temp = read_zoom_slide(biopsy_slide, x, y, highest_level, lowest_level, p_size)\n","\n","        if apply_filter: # i.e. apply filtering only for training set, s\n","          # print(\"Applying tissue filtering\")\n","          if pass_tissue_percentage(slide_image_temp, tissue_p_min, p_size, p_size): # i.e. only using if lowest label passes the tissue test\n","\n","            for current_level in range(lowest_level, highest_level + 1):\n","              slide_image = read_zoom_slide(biopsy_slide, x, y, highest_level, current_level, p_size)\n","              mask_image = read_zoom_slide(mask_slide, x, y, highest_level, current_level, p_size)\n","\n","              biopsy_list_batch.append(slide_image)\n","\n","              mask_image = read_zoom_slide(mask_slide, x, y, highest_level, current_level, p_size)\n","              if (current_level == lowest_level): # Do it with only the first image\n","                # print(\"pass_cord: \" + str(x) + \" \" + str(y) + \" \" + str(has_cancer(mask_image)), end=', ', flush=True)\n","                label_list.append(has_cancer(mask_image))\n","                                        \n","              else:\n","                continue;\n","\n","        else:  # do not apply tissue filtering for valid, test set\n","          # print(\"Not applying filtering for training set\")\n","          for current_level in range(lowest_level, highest_level + 1):\n","            slide_image = read_zoom_slide(biopsy_slide, x, y, highest_level, current_level, p_size)\n","            mask_image = read_zoom_slide(mask_slide, x, y, highest_level, current_level, p_size)\n","\n","            biopsy_list_batch.append(slide_image)\n","\n","            mask_image = read_zoom_slide(mask_slide, x, y, highest_level, current_level, p_size)\n","            if (current_level == lowest_level): # Do it with only the first image\n","              # print(\"pass_cord: \" + str(x) + \" \" + str(y) + \" \" + str(has_cancer(mask_image)), end=', ', flush=True)\n","              label_list.append(has_cancer(mask_image))\n","                                      \n","            else:\n","              continue;\n","        # print_patches(biopsy_list_batch, highest_level, current_level)\n","        # print_masks(mask_list_batch, highest_level, current_level)\n","\n","        if len(biopsy_list_batch) !=0:\n","          biopsy_list.append(biopsy_list_batch)\n","  \n","        patch_counter += 1\n","        patch_x_counter += 1\n","        x = x + int(stride / biopsy_slide.level_downsamples[highest_level] *  biopsy_slide.level_downsamples[lowest_level])\n","        \n","      else: # i.e. progress toward next 'row' below\n","        x = int(p_size/2) \n","        y = y + int(stride / biopsy_slide.level_downsamples[highest_level] *  biopsy_slide.level_downsamples[lowest_level])\n","      \n","        patch_y_counter += 1\n","        if (y < biopsy_h_high  - 299//2):\n","          patch_x_counter = 0\n","\n","    else: \n","      run = False  \n","\n","  # i.e. undersampled labels into a balanced set (i.e.same )\n","  balanced_index = undersampling_labels(label_list)\n","  label_list = [label_list[i] for i in balanced_index]\n","  biopsy_list = [biopsy_list[i] for i in balanced_index]  \n","\n","  assert len(biopsy_list) == len(label_list)\n","  print(\"tissue filtering percentage used: \", \"{:.2f}\".format(len(biopsy_list)/patch_counter*100), \"%\")\n","\n","  print(\"num of patches per zoom lev:\", len(label_list))\n","  if apply_filter: # i.e. for training set\n","    return biopsy_list, label_list\n","  \n","  else: # i.e. for test set, also returning patches_num\n","    patches_num = [patch_counter, patch_x_counter, patch_y_counter]\n","    print(\"patches num: \", patches_num)\n","    \n","    return biopsy_list, label_list, patches_num \n"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d249BrB9kg5q"},"source":["### Flatten and put train and validation set into Numpy array formats"]},{"cell_type":"code","metadata":{"id":"Is4BpB-vkFHM","executionInfo":{"status":"ok","timestamp":1608404368978,"user_tz":300,"elapsed":63747,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["# flatten each biopsy patch into its zoom level\r\n","def flatten_biopsy_zoom(biopsy_patch):\r\n","  zoom1 = []\r\n","  zoom2 = []\r\n","\r\n","  for biopsy in biopsy_patch:\r\n","    # print(np.array(biopsy).shape)\r\n","    for patch_img in biopsy:\r\n","      zoom1.append(patch_img[0])\r\n","      zoom2.append(patch_img[1])\r\n","\r\n","  assert np.array(zoom1).shape == np.array(zoom2).shape\r\n","  return  np.array(zoom1),  np.array(zoom2)\r\n","\r\n","# flatten label\r\n","def flatten_label(label_list):\r\n","  label = []\r\n","  for image in label_list:\r\n","    for i in image:\r\n","      label.append(i)\r\n","\r\n","  print(\"Total num of patches per zoom level\", len(label))\r\n","  return np.array(label)"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6t0lXiS5E6v7"},"source":["#### Save Train and Validation set as an Numpy format"]},{"cell_type":"code","metadata":{"id":"XvTGi-dc66ws","executionInfo":{"status":"ok","timestamp":1608404368979,"user_tz":300,"elapsed":63746,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["# files_list = os.listdir(saving_dir)\r\n","\r\n","# if len(files_list) != 0:\r\n","#   for file in files_list: #i.e. delete old files each time\r\n","#     os.remove(os.path.join(saving_dir,file))"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"VCqTbi3joMC0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608412902751,"user_tz":300,"elapsed":5080979,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}},"outputId":"43847c2d-9086-4726-f36c-bebefcc6dc11"},"source":["result_train =[create_patches(slide, mask, lowest_level = lowest_level, highest_level = highest_level, \n","                              apply_filter = True, stride = train_val_stride, \n","                              tissue_p_min = tissue_p_min) for slide,mask in zip(biopsy_slides_train, mask_slides_train)]\n","biopsy_patch_train = [item[0] for item in result_train]\n","label_train =[item[1] for item in result_train]\n","\n","zoom1_train, zoom2_train= flatten_biopsy_zoom(biopsy_patch_train)\n","\n","# saving files in Numpy formats\n","np.save(os.path.join(saving_dir,'zoom1_train_15.npy'),zoom1_train)\n","del zoom1_train\n","np.save(os.path.join(saving_dir,'zoom2_train_15.npy'),zoom2_train)\n","del zoom2_train\n","\n","\n","label_train = flatten_label(label_train)\n","np.save(os.path.join(saving_dir,'label_train_15.npy'),label_train)\n","del label_train"],"execution_count":21,"outputs":[{"output_type":"stream","text":["lowest dim shape: 65536   86016\n","tissue filtering percentage used:  1.99 %\n","num of patches per zoom lev: 1246\n","Total num of patches per zoom level 1246\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S5biRqTFzaEs","executionInfo":{"status":"ok","timestamp":1608412902752,"user_tz":300,"elapsed":28,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":[""],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3PMpjE2kIc7","executionInfo":{"status":"ok","timestamp":1608412902752,"user_tz":300,"elapsed":19,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":["# result_valid =[create_patches(slide, mask, lowest_level = lowest_level, highest_level = highest_level, \r\n","#                               apply_filter = True, stride = train_val_stride, tissue_p_min = tissue_p_min) for slide,mask in zip(biopsy_slides_valid, mask_slides_valid)]\r\n","# biopsy_patch_valid = [item[0] for item in result_valid]\r\n","# label_valid =[item[1] for item in result_valid]\r\n","\r\n","# zoom1_valid, zoom2_valid = flatten_biopsy_zoom(biopsy_patch_valid)\r\n","# # saving files in Numpy formats\r\n","# np.save(os.path.join(saving_dir,'zoom1_valid.npy'),zoom1_valid)\r\n","# del zoom1_valid\r\n","# np.save(os.path.join(saving_dir,'zoom2_valid.npy'),zoom2_valid)\r\n","# del zoom2_valid\r\n","\r\n","# label_valid = flatten_label(label_valid)\r\n","# np.save(os.path.join(saving_dir,'label_valid.npy'),label_valid)\r\n","# del label_valid"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"t9VA4JnwR7Vx","executionInfo":{"status":"ok","timestamp":1608412902753,"user_tz":300,"elapsed":13,"user":{"displayName":"jonathan jung","photoUrl":"","userId":"09751236818697640543"}}},"source":[""],"execution_count":22,"outputs":[]}]}